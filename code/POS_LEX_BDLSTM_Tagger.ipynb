{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"POS_LEX_BDLSTM_Tagger.ipynb","version":"0.3.2","provenance":[{"file_id":"1W6GHhtAv1zZ1Z2D6lLvC-uDSDWJD130O","timestamp":1567765261410}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ueQIwiNm42tG","colab_type":"code","outputId":"303b101a-9a49-4518-d9eb-38e2c617e70b","executionInfo":{"status":"ok","timestamp":1567550423515,"user_tz":-120,"elapsed":3945,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mClFT0ApRPzN-A5mrBkVzOsZ-tFqq5y2LMjI6Cz=s64","userId":"07183045139148849434"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["# !pip install tensorflow \n","# TensorFlow and tf.keras\n","# its just working with tensorflow 1.13.1, with others has problem\n","import tensorflow as tf\n","print(tf.__version__)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.14.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z_pjD2e15BFA","colab_type":"text"},"source":["**- goolge Colab Configuration**"]},{"cell_type":"code","metadata":{"id":"nZKvqNpW5HjM","colab_type":"code","outputId":"e9bdc060-7f39-4cf3-c533-1d7e2f62521b","executionInfo":{"status":"ok","timestamp":1568350883744,"user_tz":-120,"elapsed":22246,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"","userId":"15548690818221904033"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UTR5Csn45f2I","colab_type":"text"},"source":["**- Setting root address to project in Google Drive**"]},{"cell_type":"code","metadata":{"id":"ywAPM0ns5dX-","colab_type":"code","outputId":"aabbfcaa-d572-4e8a-a4fc-1d5ae1b780df","executionInfo":{"status":"ok","timestamp":1568350886120,"user_tz":-120,"elapsed":4626,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"","userId":"15548690818221904033"}},"colab":{"base_uri":"https://localhost:8080/","height":602}},"source":["!ls \"/content/gdrive/My Drive/NLPHW3\"\n","root_path = '/content/gdrive/My Drive/NLPHW3'"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" allWordsSensesembeddings.vec\n"," BackUpCodes\n","'Basic BDLSTM '\n"," BASIC_BDLSTM_Tagger.ipynb\n"," Basic_Tagger_Prediction.ipynb\n"," Data_Prepare_PKL_Format.ipynb\n"," Evaluation_Datasets\n","'LEX BDLSTM'\n"," LEX_BDLSTM_Tagger.ipynb\n"," Lex_Tagger_Prediction.ipynb\n"," Mask_LSTM_Model1.ipynb\n"," MFS_Tagger.ipynb\n","'POS BDLSTM'\n"," POS_BDLSTM_Tagger.ipynb\n","'POS_LEX BDLSTM'\n"," POS_LEX_BDLSTM_models_48.75846501128668\n"," POS_LEX_BDLSTM_SenseEmbed_models_47.40406320541761\n"," POS_LEX_BDLSTM_Tagger.ipynb\n"," POS_LEX_Tagger_Prediction.ipynb\n","'POS_LEX_WNDOMAIN BDLSTM '\n"," POS_LEX_WnDomain_BDLSTM_Tagger.ipynb\n"," POS_LEX_WnDomain_models_47.629796839729124\n"," POS_LEX_WnDomain_Tagger_Prediction.ipynb\n"," POS_Tagger_Prediction.ipynb\n","'POS_WNDOMAIN BDLSTM'\n"," POS_WnDomain_BDLSTM_Tagger.ipynb\n"," POS_WnDomain_SenseEmbed_models_48.53273137697517\n"," POS_WnDomain_Tagger_Prediction.ipynb\n"," resources\n"," semcor\n"," semcor+omsti\n"," Training_Corpora\n","'WNDOMAIN BDLSTM'\n"," WnDomain_BDLSTM_Tagger.ipynb\n"," WnDomain_Tagger_Prediction.ipynb\n"," WSD_Evaluation_Framework\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"waoW11y6yLmL","colab_type":"code","outputId":"75a9e08a-fd3f-4167-c1fc-18388d039c86","executionInfo":{"status":"ok","timestamp":1568350889139,"user_tz":-120,"elapsed":2490,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"","userId":"15548690818221904033"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["# Imports\n","from collections import Counter\n","import codecs\n","import xml.etree.cElementTree as etree\n","import pickle\n","import nltk\n","nltk.download('wordnet')\n","import numpy as np\n","import copy\n","from nltk.corpus import wordnet as wn\n","\n","\n","# Added Chars to dictionaries\n","UNK = \"<UNK>\"\n","PAD = \"<PAD>\"\n","\n","\n","RESOURCE_PATH = root_path+'/resources/'\n","\n","MAP_WN2BN_FILE = RESOURCE_PATH + 'babelnet2wordnet.tsv'\n","MAP_BN2WNDOMAIN_FILE = RESOURCE_PATH + 'babelnet2wndomains.tsv'\n","MAP_BN2LEXNAMES_FILE = RESOURCE_PATH + 'babelnet2lexnames.tsv'\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"epYctd54CoTK","colab_type":"code","outputId":"081aeaaf-2a2c-4d36-a65a-5a94f67b2fad","executionInfo":{"status":"ok","timestamp":1568350889477,"user_tz":-120,"elapsed":1718,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"","userId":"15548690818221904033"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["all_dict_data = pickle.load(open(root_path+'/semcor/semcor/all_dict_data.pkl', \"rb\"))\n","\n","RawWords2id = all_dict_data[\"RawWords2id\"]\n","SenseWords2id = all_dict_data[\"SenseWords2id\"]\n","pos2id = all_dict_data[\"pos2id\"]\n","lex2id = all_dict_data[\"lex2id\"]\n","wnDomain2id = all_dict_data[\"wnDomain2id\"]\n","\n","print(len(pos2id))\n","print(len(SenseWords2id))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["12\n","60919\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pT5cObkBpThO","colab_type":"code","colab":{}},"source":["# ===-----------------------------------------------------------------------===\n","# Trainig Section\n","# ===-----------------------------------------------------------------------===\n","\n","# function for add padding for train_y in every batch based on maximum length of sentence in that batch\n","# this method boost the performance of running.\n","def padding(X,padding_word):\n","\tmax_len = 0\n","\tfor x in X:\n","\t\tif len(x) > max_len:\n","\t\t\tmax_len = len(x)\n","\tpadded_X = np.ones((len(X), max_len), dtype=np.int32) * padding_word\n","\tfor i in range(len(X)):\n","\t\tfor j in range(len(X[i])):\n","\t\t\tpadded_X[i, j] = X[i][j]\n","\treturn padded_X\n","\n","\n","# padding function for train_x\n","def padding3(X,padding_word):\n","\tmax_len = 0\n","\tfor x in X:\n","\t\tif len(x) > max_len:\n","\t\t\tmax_len = len(x)\n","\tpadded_X = np.ones((len(X), max_len), dtype=np.int32) * padding_word\n","\tfor i in range(len(X)):\n","\t\tfor j in range(len(X[i])):\n","\t\t\tpadded_X[i, j] = X[i][j]\n","\treturn padded_X\n","\n","# function for calculating umber of hits and number of all predictions.\n","def number_of_batch_hits(y_batch_pred,y_batch_true):\n","    num_hits = 0\n","    num_all_chars = 0    \n","    for i in range(len(y_batch_true)):\n","        for j in range(len(y_batch_true[i])):\n","            num_all_chars = num_all_chars+1\n","            if y_batch_pred[i][j] == y_batch_true[i][j]:\n","                num_hits = num_hits+1    \n","    return num_hits, num_all_chars\n","\n","# function for calculating umber of hits and number of all predictions.\n","def number_of_batch_sense_hits(y_batch_pred,y_batch_true):\n","    num_hits = 0\n","    num_all_chars = 0    \n","    for i in range(len(y_batch_true)):\n","        for j in range(len(y_batch_true[i])):\n","            if id2Sensewords[y_batch_true[i][j]].startswith('bn'):\n","                num_all_chars = num_all_chars+1\n","                if y_batch_pred[i][j] == y_batch_true[i][j]:\n","                    num_hits = num_hits+1    \n","    return num_hits, num_all_chars\n","\n","# ----------------- Add Summary Function ------------------------------------------\n","def add_summary(writer, name, value, global_step):\n","    summary = tf.Summary(value=[tf.Summary.Value(tag=name, simple_value=value)])\n","    writer.add_summary(summary, global_step=global_step)                                 \n","    \n","\n","## ----------------------------------------------------------------------------\n","def mask_lemmaToSenses_batch(x_Raw_Sent_batch, y_allSenses_Sent_batch, y_allSenses_Sent_id_batch, SenseWords2id):\n","     \n","    max_len = 0    \n","    for inp in x_Raw_Sent_batch:\n","        if len(inp) > max_len:\n","            max_len = len(inp)\n","            \n","    mask_lemma2sense_batch = [0]*np.ones(shape = (len(x_Raw_Sent_batch), max_len, len(SenseWords2id)))\n","            \n","    for i in range(len(x_Raw_Sent_batch)):\n","        for j in range(len(x_Raw_Sent_batch[i])):\n","            for k in range(len(y_allSenses_Sent_batch[i][j])):            \n","#                 if SenseWords2id.get(y_allSenses_Sent_batch[i][j][k]) is not None:\n","                mask_lemma2sense_batch[i][j][y_allSenses_Sent_id_batch[i][j][k]] = 1    \n","#                    mask_lemma2sense_batch[rawWords_batch2id[x_Raw_Sent_batch[i][j]]][y_allSenses_Sent_id_batch[i][j][k]] = 1    \n","#                 else:\n","#                     print('not in dictionary sense is : ', y_allSenses_Sent_batch[i][j][k])\n","            \n","    return mask_lemma2sense_batch    \n","\n","#x_Raw_Sent_batch = x_Raw_Sent[:12]\n","#y_allSenses_Sent_batch = y_allSenses_Sent[:12]\n","#y_allSenses_Sent_id_batch = y_allSenses_Sent_id[:12]\n","#\n","#mask_lemma2sense_batch = mask_lemmaToSenses_batch(x_Raw_Sent_batch, y_allSenses_Sent_batch, y_allSenses_Sent_id_batch, SenseWords2id)    \n","\n","# use pretrained embeddings function, for chars we are using pretrain file and for bigram, trigram \n","# and fourgram we are using mean of embeddings of all unigrams of them\n","def reading_pretrained_sense_embeddings(filename, RawWords2id):\n","    # Reading Pretrained Embeddings from file\n","    pretrain_embeddigs = {}\n","    with codecs.open(filename, \"r\", \"utf-8\") as f:\n","        for line in f:\n","            pre_train = line.split()\n","            if len(pre_train) > 2:\n","                word = pre_train[0]\n","                if word in RawWords2id:\n","                    vec = pre_train[1:]\n","                    pretrain_embeddigs[word] = vec                \n","    \n","    print(\"pretrained embeddings files reading finished ...\")\n","    # making embeddings for all RawWords2id.\n","    embedding_dim = len(next(iter(pretrain_embeddigs.values())))\n","    out_of_vocab = 0\n","    out = np.ones((len(RawWords2id), embedding_dim))*0.001\n","    for word in RawWords2id.keys():\n","        if len(word) == 1:\n","            if word in pretrain_embeddigs.keys():        \n","                out[RawWords2id[word]]=np.array(pretrain_embeddigs[word])\n","            else:                \n","                out_of_vocab+=1\n","                np.random.uniform(-1.0, 1.0, embedding_dim)\n","        \n","    return out,out_of_vocab\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ifW2h9YyD7oi","colab_type":"code","outputId":"3e5eb63f-4fe8-4fb0-922f-e453097298b4","executionInfo":{"status":"ok","timestamp":1568350897652,"user_tz":-120,"elapsed":6966,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"","userId":"15548690818221904033"}},"colab":{"base_uri":"https://localhost:8080/","height":163}},"source":["\n","PAD_ID = RawWords2id[PAD]\n","id2Sensewords = dict(zip(SenseWords2id.values(), SenseWords2id.keys()))\n","\n","sense_embeddings, out_of_vocab = reading_pretrained_sense_embeddings(root_path + '/allWordsSensesembeddings.vec', RawWords2id)\n","print('sense_embeddings: ', len(sense_embeddings))\n","print('out_of_vocab: ', out_of_vocab)\n","\n","# we are using pretrained embedding - len(words2id)\n","VOCAB_SIZE =  len(RawWords2id)\n","WORD_EMBEDDING_DIM = 100\n","print('WORD_EMBEDDING_DIM: ', WORD_EMBEDDING_DIM)\n","print('VOCAB_SIZE: ', VOCAB_SIZE)\n","\n","# some Basic Hyper parameters\n","NUM_EPOCHS = 5\n","BATCH_SIZE = 4\n","HIDDEN_LAYER_DIM = 256\n","LEARNING_RATE = 1\n","NUM_CLASSES = len(SenseWords2id)\n","print('num sense classes: ', NUM_CLASSES)\n","L2_REGU_LAMBDA=0.0001\n","NUM_LAYERS = 2\n","CLIP=10\n","crf_lambda = 0.05\n","num_sense_pos = len(pos2id)\n","print('num_sense_pos: ', num_sense_pos)\n","num_sense_lex = len(lex2id)\n","print('num_sense_lex: ', num_sense_lex)\n","num_sense_wnDomain = len(wnDomain2id)\n","print('num_sense_wnDomain: ', num_sense_wnDomain)\n","init_lr = 0.005\n","decay_steps = 500\n","decay_rate = 0.96\n","moving_avg_deacy = 0.999\n","VERY_BIG_NUMBER = 1e30\n","\n","summaries = []\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["pretrained embeddings files reading finished ...\n","sense_embeddings:  32893\n","out_of_vocab:  5\n","WORD_EMBEDDING_DIM:  100\n","VOCAB_SIZE:  32893\n","num sense classes:  60919\n","num_sense_pos:  12\n","num_sense_lex:  46\n","num_sense_wnDomain:  160\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c7VncpqopT0M","colab_type":"code","colab":{}},"source":["\n","# --------------------- Tensorflow part ---------------------------------------------------\n","import tensorflow as tf\n","from tensorflow.contrib import layers\n","from tensorflow.contrib import crf\n","\n","def create_tensorflow_model(vocab_size, embedding_dim, hidden_layer_dim, sense_embed_bool = False, total_loss = 0):\n","    print(\"Creating TENSORFLOW model\")\n","     \n","    # Inputs have (batch_size, timesteps) shape.\n","    input_ = tf.placeholder(dtype = tf.int32, shape=[None, None], name='input_x')   \n","    # Labels have (batch_size,) shape.\n","    labels = tf.placeholder(dtype = tf.int32, shape=[None, None], name='labels_BN')\n","    \n","    y_pos = tf.placeholder(dtype = tf.int32, shape=[None, None], name='pos_tag')\n","    \n","    y_lex = tf.placeholder(dtype = tf.int32, shape=[None, None], name='lex_tag')\n","           \n","    \n","    # dropout_keep_prob is a scalar.\n","    dropout_keep_prob = tf.placeholder(dtype = tf.float32, name='dropout_keep_prob')\n","    \n","    seq_length = tf.reduce_sum(tf.cast( tf.not_equal(input_[:,:], tf.ones_like(input_[:,:] ) * PAD_ID ), tf.int32), 1)    \n","    print('seq_length: ', seq_length)\n","    \n","    max_sent_size = tf.size(input_[0,:])    \n","    print('max_sent_size: ', max_sent_size)\n","    \n","    batch_size = tf.size(input_[:,0])    \n","    print('batch_size: ', batch_size)        \n","    \n","    mask_RawTosense_batch = tf.placeholder(dtype = tf.bool, shape=[None, None, None], name='mask_Raw2Senses')    \n","    print('mask_RawTosense_batch: ', mask_RawTosense_batch)\n","    \n","    mask_pos2sense = tf.placeholder(dtype = tf.bool, shape=[None, None], name='mask_Raw2Senses')    \n","    print('mask_pos2sense: ', mask_pos2sense)\n","    mask_matrix_pos = tf.tile(tf.expand_dims(mask_pos2sense, 0), [batch_size, 1, 1])     \n","    print('mask_matrix_pos: ', mask_matrix_pos)\n","    \n","    mask_lex2sense = tf.placeholder(dtype = tf.bool, shape=[None, None], name='mask_Raw2Senses')    \n","    print('mask_lex2sense: ', mask_lex2sense)\n","    mask_matrix_lex = tf.tile(tf.expand_dims(mask_lex2sense, 0), [batch_size, 1, 1])     \n","    print('mask_matrix_lex: ', mask_matrix_lex)\n","    \n","    \n","    x_mask = tf.not_equal(input_[:,:], tf.ones_like(input_[:,:] ) * PAD_ID )    \n","    print('x_mask: ', x_mask)\n","    \n","    attention_mask = (tf.cast(x_mask, 'float') -1) * VERY_BIG_NUMBER     \n","    print('attention_mask: ', attention_mask)\n","\n","    # initialize weights randomly from a Gaussian distribution\n","    # step 1: create the initializer for weights\n","    weight_initer = tf.truncated_normal_initializer(mean=0.0, stddev=0.01)\n","        \n","## ---------------------------- embedding Block --------------------------------------------\n","## -----------------------------------------------------------------------------------------  \n","    with tf.variable_scope('embeddings', reuse=tf.AUTO_REUSE):\n","        if sense_embed_bool:\n","            embedding_matrix = tf.Variable(sense_embeddings, dtype=tf.float32, name='embedding')\n","        else:\n","            embedding_matrix = tf.get_variable(\"embeddings\", shape=[vocab_size, embedding_dim])\n","        \n","        embeddings = tf.nn.embedding_lookup(embedding_matrix, input_)        \n","        print('embeddings: ', embeddings)\n","        \n","        embeddings = tf.reshape(embeddings,[batch_size, max_sent_size, embedding_dim]) #         \n","        print('embeddings: ', embeddings)\n","\n","        embeddings=tf.nn.dropout(tf.cast(embeddings, tf.float32), dropout_keep_prob) #     embeddings shape (batch size, sentence length with padding, 100) \n","\n","        print ('embeddings is ok \\n')                \n","    \n","## --------------------------- POS Block ---------------------------------------------------\n","## -----------------------------------------------------------------------------------------  \n","\n","    with tf.variable_scope('rnn_cell_pos', reuse=tf.AUTO_REUSE):\n","            print ('lstm_cell_pos is is ok ... ')\n","            def lstm_cell1():\n","                return tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(hidden_layer_dim), output_keep_prob=dropout_keep_prob)\n","\n","            stacked_fw_lstm_pos = tf.nn.rnn_cell.MultiRNNCell(\n","                [lstm_cell1() for _ in range(NUM_LAYERS)])\n","\n","            stacked_bw_lstm_pos = tf.nn.rnn_cell.MultiRNNCell(\n","                [lstm_cell1() for _ in range(NUM_LAYERS)])\n","\n","    with tf.variable_scope('rnn_pos', reuse=tf.AUTO_REUSE):                        \n","        (forward_output_pos, backword_output_pos), _ = tf.nn.bidirectional_dynamic_rnn(\n","            cell_fw = stacked_fw_lstm_pos,\n","            cell_bw = stacked_bw_lstm_pos,\n","            inputs = embeddings,\n","            sequence_length = seq_length,\n","            dtype=tf.float32\n","        )                        \n","        outputBD_pos = tf.concat([forward_output_pos, backword_output_pos], axis=2)\n","        print('outputBD_pos: ', outputBD_pos) # shape is batch*max_len*(2*hidden_layer_size)                         \n","\n","        print ('outputBD_pos is ok \\n')\n","\n","    with tf.variable_scope(\"softmax_layer_pos\", reuse=tf.AUTO_REUSE):\n","        W_pos = tf.get_variable(\"W_pos\", shape=[2*hidden_layer_dim, num_sense_pos], initializer = weight_initer)\n","        b_pos = tf.get_variable(\"b_pos\", shape=[num_sense_pos], initializer=tf.zeros_initializer())\n","\n","        flat_softmax_pos = tf.reshape(outputBD_pos, [-1, tf.shape(outputBD_pos)[2]]) # shape is (batch*max_len)*(2*hidden_layer_size)\n","        print('flat_softmax_pos: ', flat_softmax_pos)\n","\n","        drop_flat_softmax_pos = tf.nn.dropout(flat_softmax_pos, dropout_keep_prob) # shape is (batch*max_len)*(2*hidden_layer_size)\n","        print('drop_flat_softmax_pos: ', drop_flat_softmax_pos)\n","\n","        flat_pos_logits = tf.matmul(drop_flat_softmax_pos, W_pos) + b_pos # shape is (batch*max_len)*num_sense_pos\n","        print('flat_pos_logits: ', flat_pos_logits)\n","\n","        pos_logits = tf.reshape(flat_pos_logits, [batch_size, max_sent_size, num_sense_pos]) # shape is batch*max_len*num_sense_pos ->3D\n","        print('pos_logits: ', pos_logits)\n","\n","        predict_pos = tf.argmax(pos_logits , axis=2)\n","\n","        loss_pos = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels= y_pos, logits= pos_logits))\n","\n","        total_loss = total_loss + loss_pos\n","\n","        float_mask_matrix_pos = tf.cast(mask_matrix_pos, dtype=tf.float32)\n","        print('float_mask_matrix_pos: ', float_mask_matrix_pos)\n","\n","        pos_masked_senses = tf.matmul(pos_logits, float_mask_matrix_pos) #mask_mat = 2*11*56 or batch*pos_num*NUM_CLASSES\n","        print('pos_masked_senses: ', pos_masked_senses)  # size is: batch*max_len*NUM_CLASSES\n","\n","        print ('softmax_layer_pos is ok \\n')\n","\n","\n","## --------------------------- LEX Block ---------------------------------------------------\n","## -----------------------------------------------------------------------------------------\n","    with tf.variable_scope('rnn_cell_lex', reuse=tf.AUTO_REUSE):\n","        print ('lstm_cell_lex is is ok ... ')\n","        def lstm_cell1():\n","            return tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(hidden_layer_dim), output_keep_prob=dropout_keep_prob)\n","\n","        stacked_fw_lstm_lex = tf.nn.rnn_cell.MultiRNNCell(\n","            [lstm_cell1() for _ in range(NUM_LAYERS)])\n","\n","        stacked_bw_lstm_lex = tf.nn.rnn_cell.MultiRNNCell(\n","            [lstm_cell1() for _ in range(NUM_LAYERS)])\n","\n","    with tf.variable_scope('rnn_lex', reuse=tf.AUTO_REUSE):                        \n","        (forward_output_lex, backword_output_lex), _ = tf.nn.bidirectional_dynamic_rnn(\n","            cell_fw = stacked_fw_lstm_lex,\n","            cell_bw = stacked_bw_lstm_lex,\n","            inputs = outputBD_pos,\n","            sequence_length = seq_length,\n","            dtype=tf.float32\n","        )\n","\n","        outputBD_lex = tf.concat([forward_output_lex, backword_output_lex], axis=2)\n","        print('outputBD_lex: ', outputBD_lex) # shape is batch*max_len*(2*hidden_layer_size) \n","\n","        print ('outputBD_lex is ok \\n')     \n","\n","    with tf.variable_scope(\"softmax_layer_lex\", reuse=tf.AUTO_REUSE):\n","        W_lex = tf.get_variable(\"W_lex\", shape=[2*hidden_layer_dim, num_sense_lex], initializer = weight_initer)\n","        b_lex = tf.get_variable(\"b_lex\", shape=[num_sense_lex], initializer=tf.zeros_initializer())\n","\n","        flat_softmax_lex = tf.reshape(outputBD_lex, [-1, tf.shape(outputBD_lex)[2]]) # shape is (batch*max_len)*(2*hidden_layer_size)\n","        print('flat_softmax_lex: ', flat_softmax_lex)\n","\n","        drop_flat_softmax_lex = tf.nn.dropout(flat_softmax_lex, dropout_keep_prob) # shape is (batch*max_len)*(2*hidden_layer_size)\n","        print('drop_flat_softmax_lex: ', drop_flat_softmax_lex)\n","\n","        flat_lex_logits = tf.matmul(drop_flat_softmax_lex, W_lex) + b_lex # shape is (batch*max_len)*num_sense_lex\n","        print('flat_lex_logits: ', flat_lex_logits)\n","\n","        lex_logits = tf.reshape(flat_lex_logits, [batch_size, max_sent_size, num_sense_lex]) # shape is batch*max_len*num_sense_lex ->3D\n","        print('lex_logits: ', lex_logits)\n","\n","        predict_lex = tf.argmax(lex_logits , axis=2)\n","\n","        loss_lex = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels= y_lex, logits= lex_logits))\n","        total_loss = total_loss + loss_lex\n","\n","        float_mask_matrix_lex = tf.cast(mask_matrix_lex, dtype=tf.float32)\n","        print('float_mask_matrix_lex: ', float_mask_matrix_lex)\n","\n","        lex_masked_senses = tf.matmul(lex_logits, float_mask_matrix_lex)\n","        print('lex_masked_senses: ', lex_masked_senses)\n","\n","        print ('softmax_layer_lex is ok \\n')     \n","\n","    input_rnn_sense = outputBD_lex\n","\n","## --------------------------- SENSE Block ------------------------------------------------   \n","## ----------------------------------------------------------------------------------------   \n","    with tf.variable_scope('rnn_cell_sense', reuse=tf.AUTO_REUSE):\n","            print ('lstm_sense is ok')\n","            def lstm_cell():\n","                return tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(hidden_layer_dim), output_keep_prob=dropout_keep_prob)\n","        \n","            stacked_fw_lstm_Sense = tf.nn.rnn_cell.MultiRNNCell(\n","                [lstm_cell() for _ in range(NUM_LAYERS)])\n","            \n","            stacked_bw_lstm_Sense = tf.nn.rnn_cell.MultiRNNCell(\n","                [lstm_cell() for _ in range(NUM_LAYERS)])\n","            \n","    with tf.variable_scope('rnn_sense', reuse=tf.AUTO_REUSE):                        \n","            (forward_output_Sense, backword_output_Sense), _ = tf.nn.bidirectional_dynamic_rnn(\n","                cell_fw = stacked_fw_lstm_Sense,\n","                cell_bw = stacked_bw_lstm_Sense,\n","                inputs = input_rnn_sense,\n","                sequence_length = seq_length,\n","                dtype=tf.float32\n","            )\n","            \n","            outputBD_Sense = tf.concat([forward_output_Sense, backword_output_Sense], axis=2)            \n","            print('outputBD_Sense: ', outputBD_Sense) # shape is batch*max_len*(2*hidden_layer_size) \n","            \n","            print ('outputBD_Sense is ok \\n')\n","            \n","## --------------------------- attention_layer --------------------------------------------------\n","    with tf.variable_scope(\"attention_layer\", reuse=tf.AUTO_REUSE):\n","        W_attention_L = tf.get_variable(\"W_attention_L\", shape=[2*hidden_layer_dim, 1], initializer = weight_initer )\n","        flat_outputBD_Sense = tf.reshape(outputBD_Sense, [batch_size*max_sent_size, tf.shape(outputBD_Sense)[2]])        \n","        print('flat_outputBD_Sense: ', flat_outputBD_Sense) # shape is  shape is (batch*max_length*(2*hidden_layer_size)).(51(2*hidden_layer_size)2*1) = (batch*max_length)*1 ->2D\n","        \n","        flat_outputBD_Sense_tanh = tf.tanh(flat_outputBD_Sense)\n","        \n","        u_flat_outputBD_Sense_tanh = tf.matmul(flat_outputBD_Sense_tanh, W_attention_L) # shape is batch*max_length -> 2D\n","        print('u_flat: ', u_flat_outputBD_Sense_tanh)\n","        \n","        u = tf.reshape(u_flat_outputBD_Sense_tanh, [batch_size, max_sent_size]) + attention_mask\n","        print('u: ', u)\n","        \n","        u_softmax = tf.nn.softmax(u, 1)\n","        \n","        a = tf.expand_dims(u_softmax, 2) # shape is expand to batch*max_len*1 -> 3D\n","        print('a: ', a)\n","        \n","        c = tf.reduce_sum(tf.multiply(outputBD_Sense, a), axis=1) # shape is batch*max_len*(2*hidden_layer_size) and then reduce_sum with axis 1 to: batch*(2*hidden_layer_size)\n","        print('c: ', c)\n","        \n","        tiled_c = tf.tile(tf.expand_dims(c, 1), [1, max_sent_size, 1]) # shape is batch*max_len*(2*hidden_layer_size)\n","        print('tiled_c: ', tiled_c)\n","        \n","        attention_output = tf.concat([tiled_c, outputBD_Sense], 2) # batch*max_len*(2*hidden_layer_size) \"concat with\" batch*max_len*(2*hidden_layer_size) -> batch*max_len*(4*hidden_layer_size)\n","        print('attention_output: ', attention_output)\n","        \n","        flat_attention_output = tf.reshape(attention_output, [batch_size*max_sent_size, tf.shape(attention_output)[2]]) # reshape to (batch*max_len)*(4*hidden_layer_size) -> 2D\n","        print('flat_attention_output: ', flat_attention_output)\n","\n","        print ('global_attention is ok \\n') \n","        \n","## --------------------------- hidden_layer Sense ------------------------------------------------------------\n","    with tf.variable_scope(\"hidden_layer\", reuse=tf.AUTO_REUSE):\n","        W = tf.get_variable(\"W\", shape=[4*hidden_layer_dim, 2*hidden_layer_dim], initializer = weight_initer)\n","        b = tf.get_variable(\"b\", shape=[2*hidden_layer_dim], initializer = tf.zeros_initializer())\n","        \n","        drop_flat_attention_output = tf.nn.dropout(flat_attention_output, dropout_keep_prob) # shape is (batch*max_len)*(4*hidden_layer_size) -> 2D\n","        print('drop_flat_attention_output: ', drop_flat_attention_output)\n","        \n","        hidden_layer_output = tf.matmul(drop_flat_attention_output, W) + b  # shape is (batch*max_len)*(2*hidden_layer_size) -> 2D\n","        print('hidden_layer_output: ', hidden_layer_output)\n","                \n","        print ('hidden_layer is ok \\n') \n","        \n","## --------------------------- softmax_layer Sense ------------------------------------------------------------\n","    with tf.variable_scope(\"softmax_layer\", reuse=tf.AUTO_REUSE):\n","        W_sense = tf.get_variable(\"W_sense\", shape=[2*hidden_layer_dim, NUM_CLASSES], initializer = weight_initer)\n","        b_sense = tf.get_variable(\"b_sense\", shape=[NUM_CLASSES], initializer=tf.zeros_initializer())\n","        \n","        drop_hidden_layer_output = tf.nn.dropout(hidden_layer_output, dropout_keep_prob)\n","        print('drop_hidden_layer_output: ', drop_hidden_layer_output)\n","        \n","        flat_sense_logits = tf.matmul(drop_hidden_layer_output, W_sense) + b_sense\n","        print('flat_sense_logits: ', flat_sense_logits)\n","        \n","        sense_logits = tf.reshape(flat_sense_logits, [batch_size, max_sent_size, NUM_CLASSES])\n","        print('sense_logits: ', sense_logits)                \n","        \n","        # we add combination of lex and pos masks to our logit to make a better filter of outputs to our sense logit.\n","        masked_sense_logits = tf.multiply(sense_logits, tf.multiply(pos_masked_senses, lex_masked_senses))\n","        print('masked_sense_logits: ', masked_sense_logits)  \n","\n","            \n","        float_mask_RawTosense_batch = tf.cast(mask_RawTosense_batch, dtype=tf.float32)\n","        print('float_mask_RawTosense_batch: ', float_mask_RawTosense_batch)\n","        \n","        final_sense_logits = tf.multiply(masked_sense_logits, float_mask_RawTosense_batch)\n","        print('final_sense_logits: ', final_sense_logits)\n","\n","        predictions = tf.argmax(final_sense_logits , axis=2)\n","        print('predictions: ', predictions)\n","        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels= labels, logits= final_sense_logits))\n","        total_loss = total_loss + loss\n","        print ('softmax_layer is ok \\n')\n","        \n","                      \n","## --------------------------- train_op Block ----------------------------------------------\n","## -----------------------------------------------------------------------------------------          \n","    with tf.variable_scope('train_op', reuse=tf.AUTO_REUSE):\n","                        \n","        optimizer = tf.train.AdadeltaOptimizer(LEARNING_RATE)\n","        \n","#         optimizer = tf.train.AdamOptimizer(LEARNING_RATE)\n","#         optimizer=tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE, use_locking=False, name='GradientDescent')\n","        print ('AdamOptimizer is ok .... \\n')\n","        \n","        tvars=tf.trainable_variables()\n","        print ('tvars is ok ....')\n","    \n","        l2_loss = tf.add_n([tf.nn.l2_loss(v) for v in tvars if v.get_shape().ndims > 1])\n","        print ('l2_loss is ok ....')\n","        \n","        total_loss = total_loss + L2_REGU_LAMBDA*l2_loss             \n","        print ('total_loss is ok ....')\n","        \n","        summaries.append(tf.summary.scalar(\"loss\", loss))\n","        summaries.append(tf.summary.scalar(\"total_loss\", total_loss))\n","        \n","        grads,_ = tf.clip_by_global_norm(tf.gradients(total_loss,tvars),CLIP)\n","        print ('grads is ok ....')\n","        \n","        train_op = optimizer.apply_gradients(zip(grads,tvars))\n","        print ('train_op apply_gradients is ok ....')\n","                               \n","    return input_, labels, y_pos, y_lex, mask_RawTosense_batch, train_op, predictions, dropout_keep_prob, total_loss, seq_length, mask_pos2sense, mask_lex2sense\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sjH5I--oEvI0","colab_type":"code","outputId":"b0fb03dd-d66a-4628-eadd-38b9c432a1c5","executionInfo":{"status":"ok","timestamp":1568350906608,"user_tz":-120,"elapsed":10645,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"","userId":"15548690818221904033"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# create tensorflow model without sense embedding and just basic LSTM\n","input_, labels, y_pos, y_lex, mask_RawTosense_batch, train_op, predictions, dropout_keep_prob, total_loss, seq_length, mask_pos2sense, mask_lex2sense\\\n","= create_tensorflow_model(VOCAB_SIZE, WORD_EMBEDDING_DIM, HIDDEN_LAYER_DIM, sense_embed_bool = True, total_loss = 0)\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Creating TENSORFLOW model\n","seq_length:  Tensor(\"Sum:0\", shape=(?,), dtype=int32)\n","max_sent_size:  Tensor(\"Size:0\", shape=(), dtype=int32)\n","batch_size:  Tensor(\"Size_1:0\", shape=(), dtype=int32)\n","mask_RawTosense_batch:  Tensor(\"mask_Raw2Senses:0\", shape=(?, ?, ?), dtype=bool)\n","mask_pos2sense:  Tensor(\"mask_Raw2Senses_1:0\", shape=(?, ?), dtype=bool)\n","mask_matrix_pos:  Tensor(\"Tile:0\", shape=(?, ?, ?), dtype=bool)\n","mask_lex2sense:  Tensor(\"mask_Raw2Senses_2:0\", shape=(?, ?), dtype=bool)\n","mask_matrix_lex:  Tensor(\"Tile_1:0\", shape=(?, ?, ?), dtype=bool)\n","x_mask:  Tensor(\"NotEqual_1:0\", shape=(?, ?), dtype=bool)\n","attention_mask:  Tensor(\"mul_2:0\", shape=(?, ?), dtype=float32)\n","embeddings:  Tensor(\"embeddings/embedding_lookup/Identity:0\", shape=(?, ?, 100), dtype=float32)\n","embeddings:  Tensor(\"embeddings/Reshape:0\", shape=(?, ?, 100), dtype=float32)\n","WARNING:tensorflow:From <ipython-input-8-8c5d704ce58e>:68: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","embeddings is ok \n","\n","lstm_cell_pos is is ok ... \n","WARNING:tensorflow:From <ipython-input-8-8c5d704ce58e>:78: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From <ipython-input-8-8c5d704ce58e>:81: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From <ipython-input-8-8c5d704ce58e>:92: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","outputBD_pos:  Tensor(\"rnn_pos/concat:0\", shape=(?, ?, 512), dtype=float32)\n","outputBD_pos is ok \n","\n","flat_softmax_pos:  Tensor(\"softmax_layer_pos/Reshape:0\", shape=(?, ?), dtype=float32)\n","drop_flat_softmax_pos:  Tensor(\"softmax_layer_pos/dropout/mul_1:0\", shape=(?, ?), dtype=float32)\n","flat_pos_logits:  Tensor(\"softmax_layer_pos/add:0\", shape=(?, 12), dtype=float32)\n","pos_logits:  Tensor(\"softmax_layer_pos/Reshape_1:0\", shape=(?, ?, 12), dtype=float32)\n","float_mask_matrix_pos:  Tensor(\"softmax_layer_pos/Cast:0\", shape=(?, ?, ?), dtype=float32)\n","pos_masked_senses:  Tensor(\"softmax_layer_pos/MatMul_1:0\", shape=(?, ?, ?), dtype=float32)\n","softmax_layer_pos is ok \n","\n","lstm_cell_lex is is ok ... \n","outputBD_lex:  Tensor(\"rnn_lex/concat:0\", shape=(?, ?, 512), dtype=float32)\n","outputBD_lex is ok \n","\n","flat_softmax_lex:  Tensor(\"softmax_layer_lex/Reshape:0\", shape=(?, ?), dtype=float32)\n","drop_flat_softmax_lex:  Tensor(\"softmax_layer_lex/dropout/mul_1:0\", shape=(?, ?), dtype=float32)\n","flat_lex_logits:  Tensor(\"softmax_layer_lex/add:0\", shape=(?, 46), dtype=float32)\n","lex_logits:  Tensor(\"softmax_layer_lex/Reshape_1:0\", shape=(?, ?, 46), dtype=float32)\n","float_mask_matrix_lex:  Tensor(\"softmax_layer_lex/Cast:0\", shape=(?, ?, ?), dtype=float32)\n","lex_masked_senses:  Tensor(\"softmax_layer_lex/MatMul_1:0\", shape=(?, ?, ?), dtype=float32)\n","softmax_layer_lex is ok \n","\n","lstm_sense is ok\n","outputBD_Sense:  Tensor(\"rnn_sense/concat:0\", shape=(?, ?, 512), dtype=float32)\n","outputBD_Sense is ok \n","\n","flat_outputBD_Sense:  Tensor(\"attention_layer/Reshape:0\", shape=(?, ?), dtype=float32)\n","u_flat:  Tensor(\"attention_layer/MatMul:0\", shape=(?, 1), dtype=float32)\n","u:  Tensor(\"attention_layer/add:0\", shape=(?, ?), dtype=float32)\n","a:  Tensor(\"attention_layer/ExpandDims:0\", shape=(?, ?, 1), dtype=float32)\n","c:  Tensor(\"attention_layer/Sum:0\", shape=(?, 512), dtype=float32)\n","tiled_c:  Tensor(\"attention_layer/Tile:0\", shape=(?, ?, 512), dtype=float32)\n","attention_output:  Tensor(\"attention_layer/concat:0\", shape=(?, ?, 1024), dtype=float32)\n","flat_attention_output:  Tensor(\"attention_layer/Reshape_2:0\", shape=(?, ?), dtype=float32)\n","global_attention is ok \n","\n","drop_flat_attention_output:  Tensor(\"hidden_layer/dropout/mul_1:0\", shape=(?, ?), dtype=float32)\n","hidden_layer_output:  Tensor(\"hidden_layer/add:0\", shape=(?, 512), dtype=float32)\n","hidden_layer is ok \n","\n","drop_hidden_layer_output:  Tensor(\"softmax_layer/dropout/mul_1:0\", shape=(?, 512), dtype=float32)\n","flat_sense_logits:  Tensor(\"softmax_layer/add:0\", shape=(?, 60919), dtype=float32)\n","sense_logits:  Tensor(\"softmax_layer/Reshape:0\", shape=(?, ?, 60919), dtype=float32)\n","masked_sense_logits:  Tensor(\"softmax_layer/Mul_1:0\", shape=(?, ?, 60919), dtype=float32)\n","float_mask_RawTosense_batch:  Tensor(\"softmax_layer/Cast:0\", shape=(?, ?, ?), dtype=float32)\n","final_sense_logits:  Tensor(\"softmax_layer/Mul_2:0\", shape=(?, ?, 60919), dtype=float32)\n","predictions:  Tensor(\"softmax_layer/ArgMax:0\", shape=(?, ?), dtype=int64)\n","softmax_layer is ok \n","\n","AdamOptimizer is ok .... \n","\n","tvars is ok ....\n","l2_loss is ok ....\n","total_loss is ok ....\n","grads is ok ....\n","train_op apply_gradients is ok ....\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-8O16Z0uYOjR","colab_type":"code","outputId":"5db11307-c54b-480e-f762-f2aded608df3","executionInfo":{"status":"ok","timestamp":1568350923263,"user_tz":-120,"elapsed":26199,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"","userId":"15548690818221904033"}},"colab":{"base_uri":"https://localhost:8080/","height":212}},"source":["# Train and Dev split\n","# from sklearn.model_selection import train_test_split\n","# train_x_Raw, dev_x_Raw, train_y_BN, dev_y_BN, train_y_POS, dev_y_POS, train_y_allSenses_Sent, dev_y_allSenses_Sent, train_y_allSenses_Sent_id, dev_y_allSenses_Sent_id =\\\n","#     train_test_split(x_train_Raw_Sent_id, y_train_BNsense_Sent_id, y_train_POS_Sent_id, y_train_allSenses_Sent, y_train_allSenses_Sent_id, test_size=0.01, random_state=42)\n","\n","\n","# subset_train = 50 # Put number of subset data you want for train\n","# subset_dev= 50\n","# subset_test= 50\n","\n","\n","train_path =  root_path + '/semcor/semcor/'\n","dev_path = root_path + '/semcor/semeval2007/'\n","test_path = root_path + '/semcor/semeval2013/'\n","\n","\n","x_train_Raw_Sent_id = pickle.load(open(train_path + 'x_Raw_Sent_id.pkl', \"rb\"))\n","y_train_BNsense_Sent_id = pickle.load(open(train_path + 'y_BNsense_Sent_id.pkl', \"rb\"))\n","y_train_POS_Sent_id = pickle.load(open(train_path + 'y_POS_Sent_id.pkl', \"rb\"))\n","y_train_LEX_Sent_id = pickle.load(open(train_path + 'y_Lex_Sent_id.pkl', \"rb\"))\n","y_train_allSenses_Sent = pickle.load(open(train_path + 'y_allSenses_Sent.pkl', \"rb\"))\n","y_train_allSenses_Sent_id = pickle.load(open(train_path + 'y_allSenses_Sent_id.pkl', \"rb\"))\n","\n","mask_train_lex2sense = pickle.load(open(train_path + 'mask_lex2sense.pkl', \"rb\"))\n","mask_train_pos2sense = pickle.load(open(train_path + 'mask_pos2sense.pkl', \"rb\"))\n","\n","# x_train_Raw_Sent_id = x_train_Raw_Sent_id[slice(0, subset_train)]\n","# y_train_BNsense_Sent_id = y_train_BNsense_Sent_id[slice(0, subset_train)]  \n","# y_train_POS_Sent_id = y_train_POS_Sent_id[slice(0, subset_train)]\n","# y_train_LEX_Sent_id = y_train_LEX_Sent_id[slice(0, subset_train)]  \n","# y_train_allSenses_Sent = y_train_allSenses_Sent[slice(0, subset_train)]\n","# y_train_allSenses_Sent_id = y_train_allSenses_Sent_id[slice(0, subset_train)]\n","\n","print(len(x_train_Raw_Sent_id))\n","print(len(x_train_Raw_Sent_id[0]))\n","print(len(y_train_BNsense_Sent_id[0]))\n","\n","print('train data is ok ......... ')\n","\n","x_dev_Raw_Sent = pickle.load(open(dev_path + 'x_Raw_Sent.pkl', \"rb\"))\n","x_dev_Raw_Sent_id = pickle.load(open(dev_path + 'x_Raw_Sent_id.pkl', \"rb\"))\n","y_dev_BNsense_Sent_id = pickle.load(open(dev_path + 'y_BNsense_Sent_id.pkl', \"rb\"))\n","y_dev_POS_Sent_id = pickle.load(open(dev_path + 'y_POS_Sent_id.pkl', \"rb\"))\n","y_dev_LEX_Sent_id = pickle.load(open(dev_path + 'y_Lex_Sent_id.pkl', \"rb\"))\n","y_dev_allSenses_Sent = pickle.load(open(dev_path + 'y_allSenses_Sent.pkl', \"rb\"))\n","y_dev_allSenses_Sent_id = pickle.load(open(dev_path + 'y_allSenses_Sent_id.pkl', \"rb\"))\n","\n","mask_dev_lex2sense = pickle.load(open(dev_path + 'mask_lex2sense.pkl', \"rb\"))\n","mask_dev_pos2sense = pickle.load(open(dev_path + 'mask_pos2sense.pkl', \"rb\"))\n"," \n","# x_dev_Raw_Sent_id = x_dev_Raw_Sent_id[slice(0, subset_dev)]\n","# y_dev_BNsense_Sent_id = y_dev_BNsense_Sent_id[slice(0, subset_dev)]  \n","# y_dev_POS_Sent_id = y_dev_POS_Sent_id[slice(0, subset_dev)]\n","# y_dev_LEX_Sent_id = y_dev_LEX_Sent_id[slice(0, subset_dev)]  \n","# y_dev_allSenses_Sent = y_dev_allSenses_Sent[slice(0, subset_dev)]\n","# y_dev_allSenses_Sent_id = y_dev_allSenses_Sent_id[slice(0, subset_dev)]\n","\n","print(len(x_dev_Raw_Sent_id))\n","print(len(x_dev_Raw_Sent_id[0]))\n","print(len(y_dev_BNsense_Sent_id[0]))\n","\n","print('dev data is ok ......... ')\n","    \n","x_test_Raw_Sent = pickle.load(open(test_path + 'x_Raw_Sent.pkl', \"rb\"))\n","x_test_Raw_Sent_id = pickle.load(open(test_path + 'x_Raw_Sent_id.pkl', \"rb\"))\n","y_test_BNsense_Sent_id = pickle.load(open(test_path + 'y_BNsense_Sent_id.pkl', \"rb\"))\n","y_test_POS_Sent_id = pickle.load(open(test_path + 'y_POS_Sent_id.pkl', \"rb\"))\n","y_test_allSenses_Sent = pickle.load(open(test_path + 'y_allSenses_Sent.pkl', \"rb\"))\n","y_test_allSenses_Sent_id = pickle.load(open(test_path + 'y_allSenses_Sent_id.pkl', \"rb\"))\n","\n","mask_test_lex2sense = pickle.load(open(test_path + 'mask_lex2sense.pkl', \"rb\"))\n","mask_test_pos2sense = pickle.load(open(test_path + 'mask_pos2sense.pkl', \"rb\"))\n"," \n","    \n","# x_test_Raw_Sent_id = x_test_Raw_Sent_id[slice(0, subset_test)]\n","# y_test_BNsense_Sent_id = y_test_BNsense_Sent_id[slice(0, subset_test)]  \n","# y_test_POS_Sent_id = y_test_POS_Sent_id[slice(0, subset_test)]\n","# y_test_allSenses_Sent = y_test_allSenses_Sent[slice(0, subset_test)]\n","# y_test_allSenses_Sent_id = y_test_allSenses_Sent_id[slice(0, subset_test)]\n","\n","print(len(x_test_Raw_Sent_id))\n","print(len(x_test_Raw_Sent_id[0]))\n","print(len(y_test_BNsense_Sent_id[0]))\n","\n","print('test data is ok ......... ')\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["37176\n","17\n","17\n","train data is ok ......... \n","135\n","36\n","36\n","dev data is ok ......... \n","306\n","7\n","7\n","test data is ok ......... \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KvFMmMd6mD5N","colab_type":"code","outputId":"5e10f67f-157a-486b-fcd6-3cb4014f5cac","executionInfo":{"status":"ok","timestamp":1568350949361,"user_tz":-120,"elapsed":849,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"","userId":"15548690818221904033"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["SUBSET_MODEL_ADD = root_path+'/POS_LEX_BDLSTM_SenseEmbed_models_47.40406320541761/.'\n","print(SUBSET_MODEL_ADD)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/NLPHW3/POS_LEX_BDLSTM_SenseEmbed_models_47.40406320541761/.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CC6suJoEwx_h","colab_type":"code","outputId":"f8abaa8a-6212-4949-832c-11bde2457b23","executionInfo":{"status":"ok","timestamp":1568350951790,"user_tz":-120,"elapsed":787,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"","userId":"15548690818221904033"}},"colab":{"base_uri":"https://localhost:8080/","height":66}},"source":["\n","# -----------------------------------------------------------------------------\n","def WN_to_BN_dic(mapping_file):\n","    print('WN_to_BN_dic is started ....')\n","    BN_ID = []\n","    WN_ID = []\n","    with codecs.open(mapping_file,'rb') as f:        \n","        for line in f:            \n","            line_synsets = line.decode().strip().split('\\t')\n","            BN_ID.append(line_synsets[0])\n","            WN_ID.append(line_synsets[1])    \n","    WN2BN_map_dic = dict(zip(WN_ID,BN_ID))\n","    print('WN_to_BN_dic is done ....')\n","\n","    return WN2BN_map_dic\n","\n","\n","WN2BN_map_dic = WN_to_BN_dic(MAP_WN2BN_FILE)\n","print(len(WN2BN_map_dic))\n","\n","## ----------------------------------------------------------------------------\n","def getMFS_(word, WN2BN_map_dic):\n","#     print('no prediction for: ', word)\n","    all_synsets = wn.synsets(word)\n","\n","    # check if the word has synsets or not!\n","    if len(all_synsets) == 0 or all_synsets is None:\n","        return word\n","    \n","    synset = all_synsets[0]\n","    MFS_wnId = \"wn:\" + str(synset.offset()).zfill( 8) + synset.pos()\n","    if WN2BN_map_dic.get(MFS_wnId) is not None:\n","        MFS_bnId = WN2BN_map_dic.get(MFS_wnId)\n","        \n","    return MFS_bnId\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WN_to_BN_dic is started ....\n","WN_to_BN_dic is done ....\n","117659\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J8YND8UAl9Z_","colab_type":"code","outputId":"8befe809-9d84-4096-bf07-36c8868db0a1","executionInfo":{"status":"error","timestamp":1568351131528,"user_tz":-120,"elapsed":3054,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"","userId":"15548690818221904033"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Run tensorflow model\n","saver = tf.train.Saver()\n","\n","\n","with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess: \n","    # I couln't use tensorboard because it causes my colab session to crash for big datasets.\n","    #train_writer = tf.summary.FileWriter(root_path+'logging/tensorflow_model', sess.graph)\n","    \n","    if SUBSET_MODEL_ADD is not None:\n","        saver = tf.train.Saver()\n","        saver.restore(sess, tf.train.latest_checkpoint(SUBSET_MODEL_ADD))\n","        print('model restored')\n","    else:\n","        sess.run(tf.global_variables_initializer())             \n","        print('global variable initialized')\n","        \n","    print ('start session is ok ....')\n","        \n","    for epoch in range(NUM_EPOCHS):        \n","        #train\n","        train_loss=[]    \n","        for i in range(0, len(x_train_Raw_Sent_id), BATCH_SIZE):\n","            # slice dataset for padding\n","                        \n","            batch_x_Raw = x_train_Raw_Sent_id[slice(i, i + BATCH_SIZE)]\n","            batch_y_BN = y_train_BNsense_Sent_id[slice(i, i + BATCH_SIZE)]\n","            batch_y_POS = y_train_POS_Sent_id[slice(i, i + BATCH_SIZE)]            \n","            batch_y_LEX = y_train_LEX_Sent_id[slice(i, i + BATCH_SIZE)]            \n","            y_train_allSenses_Sent_batch = y_train_allSenses_Sent[slice(i, i + BATCH_SIZE)]\n","            y_train_allSenses_Sent_id_batch = y_train_allSenses_Sent_id[slice(i, i + BATCH_SIZE)]\n","            mask_lemma2Sense_b = mask_lemmaToSenses_batch(batch_x_Raw, y_train_allSenses_Sent_batch, y_train_allSenses_Sent_id_batch, SenseWords2id)\n","            \n","            \n","            batch_x_Raw = padding3(batch_x_Raw, PAD_ID)\n","            batch_y_BN = padding(batch_y_BN, PAD_ID)\n","            batch_y_POS = padding(batch_y_POS, PAD_ID)            \n","            batch_y_LEX = padding(batch_y_LEX, PAD_ID)\n","            \n","            # runnig training session ang getting train loss for every batch and append in epoch loss\n","            _, loss_other = sess.run(\n","                [train_op, total_loss], feed_dict = { input_ : batch_x_Raw, labels : batch_y_BN, y_pos : batch_y_POS, y_lex : batch_y_LEX,\\\n","                                                     mask_RawTosense_batch : mask_lemma2Sense_b, mask_pos2sense: mask_train_pos2sense ,\\\n","                                                     mask_lex2sense : mask_train_lex2sense,  dropout_keep_prob : 0.3 })\n","            \n","            train_loss.append(loss_other)            \n","            \n","            if i % (BATCH_SIZE * 200) == 0:                \n","                print ('Train batch %d loss %f' % (i, loss_other))\n","                \n","        train_loss=np.mean(train_loss,dtype=float)                \n","        print ('Train Epoch %d loss %f' % (epoch+1, train_loss))        \n","        print('--------------------------------') \n","        \n","                                       \n","#         #Dev\n","        dev_loss=[]\n","        dev_pred=[]\n","        dev_hit_all=0\n","        dev_all_char=0        \n","        for i in range(0, len(x_dev_Raw_Sent_id), BATCH_SIZE):            \n","            \n","            batch_x_Lemma = x_dev_Raw_Sent[slice(i, i + BATCH_SIZE)]\n","            batch_x_Raw = x_dev_Raw_Sent_id[slice(i, i + BATCH_SIZE)]\n","            batch_y_BN = y_dev_BNsense_Sent_id[slice(i, i + BATCH_SIZE)]\n","            batch_y_POS = y_dev_POS_Sent_id[slice(i, i + BATCH_SIZE)]            \n","            batch_y_LEX = y_dev_LEX_Sent_id[slice(i, i + BATCH_SIZE)]\n","            \n","            y_dev_allSenses_Sent_batch = y_dev_allSenses_Sent[slice(i, i + BATCH_SIZE)]\n","            y_dev_allSenses_Sent_id_batch = y_dev_allSenses_Sent_id[slice(i, i + BATCH_SIZE)]            \n","            mask_lemma2Sense_b = mask_lemmaToSenses_batch(batch_x_Raw, y_dev_allSenses_Sent_batch, y_dev_allSenses_Sent_id_batch, SenseWords2id)            \n","            \n","            batch_x_Raw = padding3(batch_x_Raw, PAD_ID)\n","            batch_y_BN = padding(batch_y_BN, PAD_ID)\n","            batch_y_POS = padding(batch_y_POS, PAD_ID)\n","            batch_y_LEX = padding(batch_y_LEX, PAD_ID)\n","\n","            \n","            loss_other, lengths, predict = sess.run(\n","                [total_loss, seq_length, predictions], feed_dict = {input_ : batch_x_Raw, labels : batch_y_BN, y_pos : batch_y_POS, y_lex : batch_y_LEX,\\\n","                                                                                        mask_RawTosense_batch : mask_lemma2Sense_b, mask_pos2sense: mask_dev_pos2sense ,\\\n","                                                                                        mask_lex2sense : mask_dev_lex2sense, dropout_keep_prob: 1.0 })\n","            \n","            batch_true = y_dev_BNsense_Sent_id[slice(i, i + BATCH_SIZE)]\n","        \n","            pred_sense = []\n","            true_sense = []            \n","            for p in range(len(predict)):\n","                pr = []\n","                tr = []\n","                for L_ in range(lengths[p]):\n","                    # if our prediction is UNK means that word is not in our dictionary and we can't predict anything for that, so we put BackOff plan and MFS as our prediction.\n","                    if id2Sensewords[predict[p][L_]] != UNK:\n","                        pr.append(id2Sensewords[predict[p][L_]])\n","                    else:\n","                        pr.append(getMFS_(batch_x_Lemma[p][L_], WN2BN_map_dic))\n","#                         print(getMFS_(batch_x_Lemma[p][L_], WN2BN_map_dic))                        \n","                                                        \n","                    tr.append(id2Sensewords[batch_true[p][L_]])\n","                print(pr)\n","                print(tr)\n","                print('\\n')\n","                pred_sense.append(pr)\n","                true_sense.append(tr)\n","                        \n","            batch_pred = []\n","            for p in range(len(predict)):                \n","                dev_pred.append(predict[p][:lengths[p]])\n","                batch_pred.append(predict[p][:lengths[p]])\n","                \n","#             print('\\n')\n","            dev_batch_hit, dev_batch_char = number_of_batch_sense_hits(batch_pred, batch_true)            \n","            print('dev batch %d loss %f dev_batch_hit:%d dev_batch_char:%d batch_accuracy:%f' % (i, loss_other, dev_batch_hit, dev_batch_char, (dev_batch_hit/dev_batch_char)*100 ))\n","            dev_loss.append(loss_other)            \n","            dev_hit_all+=dev_batch_hit\n","            dev_all_char+=dev_batch_char\n","                \n","        dev_loss=np.mean(dev_loss,dtype=float)\n","        dev_acc = (dev_hit_all/dev_all_char)*100\n","        print('Valid Epoch %d loss %f' % (epoch+1,dev_loss))        \n","        print('dev_hit_all:%d dev_all_char:%d accuracy:%f' % (dev_hit_all,dev_all_char,dev_acc ))\n","        print('--------------------------------')\n","\n","        \n","        save_path = saver.save(sess, root_path+'/POS_LEX_BDLSTM_SenseEmbed_models_{}/model.ckpt'.format(dev_acc))\n","        print(\"Model saved in path: %s\" % save_path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/NLPHW3/POS_LEX_BDLSTM_SenseEmbed_models_47.40406320541761/model.ckpt\n"],"name":"stdout"},{"output_type":"error","ename":"NotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: Key embeddings/embedding not found in checkpoint\n\t [[{{node save_3/RestoreV2}}]]\n\t [[save_3/RestoreV2/_121]]\n  (1) Not found: Key embeddings/embedding not found in checkpoint\n\t [[{{node save_3/RestoreV2}}]]\n0 successful operations.\n0 derived errors ignored.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1286\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: Key embeddings/embedding not found in checkpoint\n\t [[node save_3/RestoreV2 (defined at <ipython-input-16-d9c03f2a3982>:9) ]]\n\t [[save_3/RestoreV2/_121]]\n  (1) Not found: Key embeddings/embedding not found in checkpoint\n\t [[node save_3/RestoreV2 (defined at <ipython-input-16-d9c03f2a3982>:9) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save_3/RestoreV2':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-d9c03f2a3982>\", line 9, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 825, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1295\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m   \u001b[0mobject_graph_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBJECT_GRAPH_PROTO_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m   \u001b[0mobject_graph_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrackable_object_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableObjectGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader_GetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-d9c03f2a3982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mSUBSET_MODEL_ADD\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSUBSET_MODEL_ADD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model restored'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1302\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\n2 root error(s) found.\n  (0) Not found: Key embeddings/embedding not found in checkpoint\n\t [[node save_3/RestoreV2 (defined at <ipython-input-16-d9c03f2a3982>:9) ]]\n\t [[save_3/RestoreV2/_121]]\n  (1) Not found: Key embeddings/embedding not found in checkpoint\n\t [[node save_3/RestoreV2 (defined at <ipython-input-16-d9c03f2a3982>:9) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save_3/RestoreV2':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-d9c03f2a3982>\", line 9, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 825, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"]}]},{"cell_type":"code","metadata":{"id":"5S61PgZodpQ7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}